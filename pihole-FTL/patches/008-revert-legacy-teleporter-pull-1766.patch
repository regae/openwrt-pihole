--- a/src/api/teleporter.c
+++ b/src/api/teleporter.c
@@ -15,18 +15,8 @@
 #include "api/api.h"
 // ERRBUF_SIZE
 #include "config/dnsmasq_config.h"
-// inflate_buffer()
-#include "zip/gzip.h"
-// find_file_in_tar()
-#include "zip/tar.h"
-// sqlite3_open_v2()
-#include "database/sqlite3.h"
-// dbquery()
-#include "database/common.h"
-// MAX_ROTATIONS
-#include "files.h"
 
-#define MAXFILESIZE (50u*1024*1024)
+#define MAXZIPSIZE (50u*1024*1024)
 
 static int api_teleporter_GET(struct ftl_conn *api)
 {
@@ -68,9 +58,9 @@ static int api_teleporter_GET(struct ftl
 struct upload_data {
 	bool too_large;
 	char *sid;
-	uint8_t *data;
-	char *filename;
-	size_t filesize;
+	char *zip_data;
+	char *zip_filename;
+	size_t zip_size;
 };
 
 // Callback function for CivetWeb to determine which fields we want to receive
@@ -89,7 +79,7 @@ static int field_found(const char *key,
 	is_sid = false;
 	if(strcasecmp(key, "file") == 0 && filename && *filename)
 	{
-		data->filename = strdup(filename);
+		data->zip_filename = strdup(filename);
 		is_file = true;
 		return MG_FORM_FIELD_STORAGE_GET;
 	}
@@ -113,21 +103,21 @@ static int field_get(const char *key, co
 
 	if(is_file)
 	{
-		if(data->filesize + valuelen > MAXFILESIZE)
+		if(data->zip_size + valuelen > MAXZIPSIZE)
 		{
-			log_warn("Uploaded Teleporter file is too large (limit is %u bytes)",
-			         MAXFILESIZE);
+			log_warn("Uploaded Teleporter ZIP archive is too large (limit is %u bytes)",
+			         MAXZIPSIZE);
 			data->too_large = true;
 			return MG_FORM_FIELD_HANDLE_ABORT;
 		}
-		// Allocate memory for the raw file data
-		data->data = realloc(data->data, data->filesize + valuelen);
-		// Copy the raw file data
-		memcpy(data->data + data->filesize, value, valuelen);
-		// Store the size of the file raw data
-		data->filesize += valuelen;
-		log_debug(DEBUG_API, "Received file (%zu bytes, buffer is now %zu bytes)",
-		          valuelen, data->filesize);
+		// Allocate memory for the raw ZIP archive data
+		data->zip_data = realloc(data->zip_data, data->zip_size + valuelen);
+		// Copy the raw ZIP archive data
+		memcpy(data->zip_data + data->zip_size, value, valuelen);
+		// Store the size of the ZIP archive raw data
+		data->zip_size += valuelen;
+		log_debug(DEBUG_API, "Received ZIP archive (%zu bytes, buffer is now %zu bytes)",
+		          valuelen, data->zip_size);
 	}
 	else if(is_sid)
 	{
@@ -153,28 +143,24 @@ static int field_stored(const char *path
 static int free_upload_data(struct upload_data *data)
 {
 	// Free allocated memory
-	if(data->filename)
+	if(data->zip_filename)
 	{
-		free(data->filename);
-		data->filename = NULL;
+		free(data->zip_filename);
+		data->zip_filename = NULL;
 	}
 	if(data->sid)
 	{
 		free(data->sid);
 		data->sid = NULL;
 	}
-	if(data->data)
+	if(data->zip_data)
 	{
-		free(data->data);
-		data->data = NULL;
+		free(data->zip_data);
+		data->zip_data = NULL;
 	}
 	return 0;
 }
 
-// Private function prototypes
-static int process_received_zip(struct ftl_conn *api, struct upload_data *data);
-static int process_received_tar_gz(struct ftl_conn *api, struct upload_data *data);
-
 static int api_teleporter_POST(struct ftl_conn *api)
 {
 	struct upload_data data;
@@ -184,7 +170,7 @@ static int api_teleporter_POST(struct ft
 
 	// Disallow large ZIP archives (> 50 MB) to prevent DoS attacks.
 	// Typically, the ZIP archive size should be around 30-100 kB.
-	if(req_info->content_length > MAXFILESIZE)
+	if(req_info->content_length > MAXZIPSIZE)
 	{
 		free_upload_data(&data);
 		return send_json_error(api, 400,
@@ -205,7 +191,7 @@ static int api_teleporter_POST(struct ft
 	}
 
 	// Check if we received something we consider being a file
-	if(data.data == NULL || data.filesize == 0)
+	if(data.zip_data == NULL || data.zip_size == 0)
 	{
 		free_upload_data(&data);
 		return send_json_error(api, 400,
@@ -223,46 +209,28 @@ static int api_teleporter_POST(struct ft
 		                       "ZIP archive too large",
 		                       NULL);
 	}
+/*
+	// Set the payload to the SID we received (if available)
+	if(data.sid != NULL)
+	{
+		const size_t bufsize = strlen(data.sid) + 5;
+		api->payload.raw = calloc(bufsize, sizeof(char));
+		strncpy(api->payload.raw, "sid=", 5);
+		strncat(api->payload.raw, data.sid, bufsize - 4);
+	}
 
-	// Check if we received something that claims to be a ZIP archive
-	// - filename should end in ".zip"
-	// - the data itself
-	//   - should be at least 40 bytes long
-	//   - start with 0x04034b50 (local file header signature, see https://pkware.cachefly.net/webdocs/APPNOTE/APPNOTE-6.3.9.TXT)
-	if(strlen(data.filename) > 4 &&
-	   strcmp(data.filename + strlen(data.filename) - 4, ".zip") == 0 &&
-	   data.filesize >= 40 &&
-	   memcmp(data.data, "\x50\x4b\x03\x04", 4) == 0)
-	{
-		return process_received_zip(api, &data);
-	}
-	// Check if we received something that claims to be a TAR.GZ archive
-	// - filename should end in ".tar.gz"
-	// - the data itself
-	//   - should be at least 40 bytes long
-	//   - start with 0x8b1f (local file header signature, see https://www.ietf.org/rfc/rfc1952.txt)
-	else if(strlen(data.filename) > 7 &&
-	        strcmp(data.filename + strlen(data.filename) - 7, ".tar.gz") == 0 &&
-	        data.filesize >= 40 &&
-	        memcmp(data.data, "\x1f\x8b", 2) == 0)
+	// Check if the client is authorized to use this API endpoint
+	if(check_client_auth(api) == API_AUTH_UNAUTHORIZED)
 	{
-		return process_received_tar_gz(api, &data);
+		free_upload_data(&data);
+		return send_json_unauthorized(api);
 	}
-
-	// else: invalid file
-	free_upload_data(&data);
-	return send_json_error(api, 400,
-	                       "bad_request",
-	                       "Invalid file",
-	                       "The uploaded file does not appear to be a valid Pi-hole Teleporter archive");
-}
-
-static int process_received_zip(struct ftl_conn *api, struct upload_data *data)
-{
+*/
+	// Process what we received
 	char hint[ERRBUF_SIZE];
 	memset(hint, 0, sizeof(hint));
 	cJSON *json_files = JSON_NEW_ARRAY();
-	const char *error = read_teleporter_zip(data->data, data->filesize, hint, json_files);
+	const char *error = read_teleporter_zip(data.zip_data, data.zip_size, hint, json_files);
 	if(error != NULL)
 	{
 		const size_t msglen = strlen(error) + strlen(hint) + 4;
@@ -274,7 +242,7 @@ static int process_received_zip(struct f
 			strcat(msg, ": ");
 			strcat(msg, hint);
 		}
-		free_upload_data(data);
+		free_upload_data(&data);
 		return send_json_error_free(api, 400,
 		                            "bad_request",
 		                            "Invalid ZIP archive",
@@ -282,7 +250,7 @@ static int process_received_zip(struct f
 	}
 
 	// Free allocated memory
-	free_upload_data(data);
+	free_upload_data(&data);
 
 	// Send response
 	cJSON *json = JSON_NEW_OBJECT();
@@ -290,445 +258,6 @@ static int process_received_zip(struct f
 	JSON_SEND_OBJECT(json);
 }
 
-static struct teleporter_files {
-	const char *filename; // Filename of the file in the archive
-	const char *table_name; // Name of the table in the database
-	const int listtype; // Type of list (only used for domainlist table)
-	const size_t num_columns; // Number of columns in the table
-	const char *columns[10]; // List of columns in the table
-} teleporter_v5_files[] = {
-	{
-		.filename = "adlist.json",
-		.table_name = "adlist",
-		.listtype = -1,
-		.num_columns = 10,
-		.columns = { "id", "address", "enabled", "date_added", "date_modified", "comment", "date_updated", "number", "invalid_domains", "status" } // abp_entries and type are not defined in Pi-hole v5.x
-	},{
-		.filename = "adlist_by_group.json",
-		.table_name = "adlist_by_group",
-		.listtype = -1,
-		.num_columns = 2,
-		.columns = { "group_id", "adlist_id" }
-	},{
-		.filename = "blacklist.exact.json",
-		.table_name = "domainlist",
-		.listtype = 1, // GRAVITY_DOMAINLIST_DENY_EXACT
-		.num_columns = 7,
-		.columns = { "id", "domain", "enabled", "date_added", "date_modified", "comment", "type" }
-	},{
-		.filename = "blacklist.regex.json",
-		.table_name = "domainlist",
-		.listtype = 3, // GRAVITY_DOMAINLIST_DENY_REGEX
-		.num_columns = 7,
-		.columns = { "id", "domain", "enabled", "date_added", "date_modified", "comment", "type" }
-	},{
-		.filename = "client.json",
-		.table_name = "client",
-		.listtype = -1,
-		.num_columns = 5,
-		.columns = { "id", "ip", "date_added", "date_modified", "comment" }
-	},{
-		.filename = "client_by_group.json",
-		.table_name = "client_by_group",
-		.listtype = -1,
-		.num_columns = 2,
-		.columns = { "group_id", "client_id" }
-	},{
-		.filename = "domainlist_by_group.json",
-		.table_name = "domainlist_by_group",
-		.listtype = -1,
-		.num_columns = 2,
-		.columns = { "group_id", "domainlist_id" }
-	},{
-		.filename = "group.json",
-		.table_name = "group",
-		.listtype = -1,
-		.num_columns = 6,
-		.columns = { "id", "enabled", "name", "date_added", "date_modified", "description" }
-	},{
-		.filename = "whitelist.exact.json",
-		.table_name = "domainlist",
-		.listtype = 0, // GRAVITY_DOMAINLIST_ALLOW_EXACT
-		.num_columns = 7,
-		.columns = { "id", "domain", "enabled", "date_added", "date_modified", "comment", "type" }
-	},{
-		.filename = "whitelist.regex.json",
-		.table_name = "domainlist",
-		.listtype = 2, // GRAVITY_DOMAINLIST_ALLOW_REGEX
-		.num_columns = 7,
-		.columns = { "id", "domain", "enabled", "date_added", "date_modified", "comment", "type" }
-	}
-};
-
-static bool import_json_table(cJSON *json, struct teleporter_files *file)
-{
-	// Check if the JSON object is an array
-	if(!cJSON_IsArray(json))
-	{
-		log_err("import_json_table(%s): JSON object is not an array", file->filename);
-		return false;
-	}
-
-	// Check if the JSON array is empty, if so, we can return early
-	const int num_entries = cJSON_GetArraySize(json);
-
-	// Check if all the JSON entries contain all the expected columns
-	cJSON *json_object = NULL;
-	cJSON_ArrayForEach(json_object, json)
-	{
-		if(!cJSON_IsObject(json_object))
-		{
-			log_err("import_json_table(%s): JSON array does not contain objects", file->filename);
-			return false;
-		}
-
-		// If this is a record for the domainlist table, add type/kind
-		if(strcmp(file->table_name, "domainlist") == 0)
-		{
-			// Add type/kind to the JSON object
-			cJSON_AddNumberToObject(json_object, "type", file->listtype);
-		}
-
-		// Check if the JSON object contains the expected columns
-		for(size_t i = 0; i < file->num_columns; i++)
-		{
-			if(cJSON_GetObjectItemCaseSensitive(json_object, file->columns[i]) == NULL)
-			{
-				log_err("import_json_table(%s): JSON object does not contain column \"%s\"", file->filename, file->columns[i]);
-				return false;
-			}
-		}
-	}
-
-	log_info("import_json_table(%s): JSON array contains %d entr%s", file->filename, num_entries, num_entries == 1 ? "y" : "ies");
-
-	// Open database connection
-	sqlite3 *db = NULL;
-	if(sqlite3_open_v2(config.files.gravity.v.s, &db, SQLITE_OPEN_READWRITE, NULL) != SQLITE_OK)
-	{
-		log_err("import_json_table(%s): Unable to open database file \"%s\": %s",
-		        file->filename, config.files.database.v.s, sqlite3_errmsg(db));
-		sqlite3_close(db);
-		return false;
-	}
-
-	// Disable foreign key constraints
-	if(sqlite3_exec(db, "PRAGMA foreign_keys = OFF;", NULL, NULL, NULL) != SQLITE_OK)
-	{
-		log_err("import_json_table(%s): Unable to disable foreign key constraints: %s", file->filename, sqlite3_errmsg(db));
-		sqlite3_close(db);
-		return false;
-	}
-
-	// Start transaction
-	if(sqlite3_exec(db, "BEGIN TRANSACTION;", NULL, NULL, NULL) != SQLITE_OK)
-	{
-		log_err("import_json_table(%s): Unable to start transaction: %s", file->filename, sqlite3_errmsg(db));
-		sqlite3_close(db);
-		return false;
-	}
-
-	// Clear existing table entries
-	if(file->listtype < 0)
-	{
-		// Delete all entries in the table
-		log_debug(DEBUG_API, "import_json_table(%s): Deleting all entries from table \"%s\"", file->filename, file->table_name);
-		if(dbquery(db, "DELETE FROM \"%s\";", file->table_name) != SQLITE_OK)
-		{
-			log_err("import_json_table(%s): Unable to delete entries from table \"%s\": %s",
-			        file->filename, file->table_name, sqlite3_errmsg(db));
-			sqlite3_close(db);
-			return false;
-		}
-	}
-	else
-	{
-		// Delete all entries in the table of the same type
-		log_debug(DEBUG_API, "import_json_table(%s): Deleting all entries from table \"%s\" of type %d", file->filename, file->table_name, file->listtype);
-		if(dbquery(db, "DELETE FROM \"%s\" WHERE type = %d;", file->table_name, file->listtype) != SQLITE_OK)
-		{
-			log_err("import_json_table(%s): Unable to delete entries from table \"%s\": %s",
-			        file->filename, file->table_name, sqlite3_errmsg(db));
-			sqlite3_close(db);
-			return false;
-		}
-	}
-
-	// Build dynamic SQL insertion statement
-	// "INSERT OR IGNORE INTO table (column1, column2, ...) VALUES (?, ?, ...);"
-	char *sql = sqlite3_mprintf("INSERT OR IGNORE INTO \"%s\" (", file->table_name);
-	for(size_t i = 0; i < file->num_columns; i++)
-	{
-		char *sql2 = sqlite3_mprintf("%s%s", sql, file->columns[i]);
-		sqlite3_free(sql);
-		sql = NULL;
-		if(i < file->num_columns - 1)
-		{
-			sql = sqlite3_mprintf("%s, ", sql2);
-			sqlite3_free(sql2);
-			sql2 = NULL;
-		}
-		else
-		{
-			sql = sqlite3_mprintf("%s) VALUES (", sql2);
-			sqlite3_free(sql2);
-			sql2 = NULL;
-		}
-	}
-	for(size_t i = 0; i < file->num_columns; i++)
-	{
-		char *sql2 = sqlite3_mprintf("%s?", sql);
-		sqlite3_free(sql);
-		sql = NULL;
-		if(i < file->num_columns - 1)
-		{
-			sql = sqlite3_mprintf("%s, ", sql2);
-			sqlite3_free(sql2);
-			sql2 = NULL;
-		}
-		else
-		{
-			sql = sqlite3_mprintf("%s);", sql2);
-			sqlite3_free(sql2);
-			sql2 = NULL;
-		}
-	}
-
-	// Prepare SQL statement
-	sqlite3_stmt *stmt = NULL;
-	if(sqlite3_prepare_v2(db, sql, -1, &stmt, NULL) != SQLITE_OK)
-	{
-		log_err("Unable to prepare SQL statement: %s", sqlite3_errmsg(db));
-		sqlite3_free(sql);
-		sqlite3_close(db);
-		return false;
-	}
-
-	// Free allocated memory
-	sqlite3_free(sql);
-	sql = NULL;
-
-	// Iterate over all JSON objects
-	cJSON_ArrayForEach(json_object, json)
-	{
-		// Bind values to SQL statement
-		for(size_t i = 0; i < file->num_columns; i++)
-		{
-			cJSON *json_value = cJSON_GetObjectItemCaseSensitive(json_object, file->columns[i]);
-			if(cJSON_IsString(json_value))
-			{
-				// Bind string value
-				if(sqlite3_bind_text(stmt, i + 1, json_value->valuestring, -1, SQLITE_STATIC) != SQLITE_OK)
-				{
-					log_err("Unable to bind text value to SQL statement: %s", sqlite3_errmsg(db));
-					sqlite3_finalize(stmt);
-					sqlite3_close(db);
-					return false;
-				}
-			}
-			else if(cJSON_IsNumber(json_value))
-			{
-				// Bind integer value
-				if(sqlite3_bind_int(stmt, i + 1, json_value->valueint) != SQLITE_OK)
-				{
-					log_err("Unable to bind integer value to SQL statement: %s", sqlite3_errmsg(db));
-					sqlite3_finalize(stmt);
-					sqlite3_close(db);
-					return false;
-				}
-			}
-			else if(cJSON_IsNull(json_value))
-			{
-				// Bind NULL value
-				if(sqlite3_bind_null(stmt, i + 1) != SQLITE_OK)
-				{
-					log_err("Unable to bind NULL value to SQL statement: %s", sqlite3_errmsg(db));
-					sqlite3_finalize(stmt);
-					sqlite3_close(db);
-					return false;
-				}
-			}
-			else
-			{
-				log_err("Unable to bind value to SQL statement: type = %X", (unsigned int)json_value->type & 0xFF);
-				sqlite3_finalize(stmt);
-				sqlite3_close(db);
-				return false;
-			}
-		}
-
-		// Execute SQL statement
-		if(sqlite3_step(stmt) != SQLITE_DONE)
-		{
-			log_err("Unable to execute SQL statement: %s", sqlite3_errmsg(db));
-			sqlite3_finalize(stmt);
-			sqlite3_close(db);
-			return false;
-		}
-
-		// Reset SQL statement
-		if(sqlite3_reset(stmt) != SQLITE_OK)
-		{
-			log_err("Unable to reset SQL statement: %s", sqlite3_errmsg(db));
-			sqlite3_finalize(stmt);
-			sqlite3_close(db);
-			return false;
-		}
-	}
-
-	// Finalize SQL statement
-	if(sqlite3_finalize(stmt) != SQLITE_OK)
-	{
-		log_err("Unable to finalize SQL statement: %s", sqlite3_errmsg(db));
-		sqlite3_close(db);
-		return false;
-	}
-
-	// Commit transaction
-	if(sqlite3_exec(db, "COMMIT;", NULL, NULL, NULL) != SQLITE_OK)
-	{
-		log_err("Unable to commit transaction: %s", sqlite3_errmsg(db));
-		sqlite3_close(db);
-		return false;
-	}
-
-	// Close database connection
-	sqlite3_close(db);
-
-	return true;
-}
-
-static int process_received_tar_gz(struct ftl_conn *api, struct upload_data *data)
-{
-	// Try to decompress the received data
-	uint8_t *archive = NULL;
-	mz_ulong archive_size = 0u;
-	if(!inflate_buffer(data->data, data->filesize, &archive, &archive_size))
-	{
-		free_upload_data(data);
-		return send_json_error(api, 400,
-		                       "bad_request",
-		                       "Invalid GZIP archive",
-		                       "The uploaded file does not appear to be a valid gzip archive - decompression failed");
-	}
-
-	// Print all files in the TAR archive if in debug mode
-	if(config.debug.api.v.b)
-	{
-		cJSON *json_files = list_files_in_tar(archive, archive_size);
-
-		cJSON *file = NULL;
-		cJSON_ArrayForEach(file, json_files)
-		{
-			const cJSON *name = cJSON_GetObjectItemCaseSensitive(file, "name");
-			const cJSON *size = cJSON_GetObjectItemCaseSensitive(file, "size");
-			if(name == NULL || size == NULL)
-				continue;
-
-			log_debug(DEBUG_API, "Found file in TAR archive: \"%s\" (%d bytes)",
-			          name->valuestring, size->valueint);
-		}
-	}
-
-	// Parse JSON files in the TAR archive
-	cJSON *imported_files = JSON_NEW_ARRAY();
-	for(size_t i = 0; i < sizeof(teleporter_v5_files) / sizeof(struct teleporter_files); i++)
-	{
-		size_t fileSize = 0u;
-		cJSON *json = NULL;
-		const char *file = find_file_in_tar(archive, archive_size, teleporter_v5_files[i].filename, &fileSize);
-		if(file != NULL && fileSize > 0u && (json = cJSON_ParseWithLength(file, fileSize)) != NULL)
-			if(import_json_table(json, &teleporter_v5_files[i]))
-				JSON_COPY_STR_TO_ARRAY(imported_files, teleporter_v5_files[i].filename);
-	}
-
-	// Temporarily write further files to to disk so we can import them on restart
-	struct {
-		const char *archive_name;
-		const char *destination;
-	} extract_files[] = {
-		{
-			.archive_name = "custom.list",
-			.destination = DNSMASQ_CUSTOM_LIST_LEGACY
-		},{
-			.archive_name = "dhcp.leases",
-			.destination = DHCPLEASESFILE
-		},{
-			.archive_name = "pihole-FTL.conf",
-			.destination = GLOBALCONFFILE_LEGACY
-		},{
-			.archive_name = "setupVars.conf",
-			.destination = config.files.setupVars.v.s
-		}
-	};
-	for(size_t i = 0; i < sizeof(extract_files) / sizeof(*extract_files); i++)
-	{
-		size_t fileSize = 0u;
-		const char *file = find_file_in_tar(archive, archive_size, extract_files[i].archive_name, &fileSize);
-		if(file != NULL && fileSize > 0u)
-		{
-			// Write file to disk
-			log_info("Writing file \"%s\" (%zu bytes) to \"%s\"",
-			         extract_files[i].archive_name, fileSize, extract_files[i].destination);
-			FILE *fp = fopen(extract_files[i].destination, "wb");
-			if(fp == NULL)
-			{
-				log_err("Unable to open file \"%s\" for writing: %s", extract_files[i].destination, strerror(errno));
-				continue;
-			}
-			if(fwrite(file, fileSize, 1, fp) != 1)
-			{
-				log_err("Unable to write file \"%s\": %s", extract_files[i].destination, strerror(errno));
-				fclose(fp);
-				continue;
-			}
-			fclose(fp);
-			JSON_COPY_STR_TO_ARRAY(imported_files, extract_files[i].destination);
-		}
-	}
-
-	// Append WEB_PORTS to setupVars.conf
-	FILE *fp = fopen(config.files.setupVars.v.s, "a");
-	if(fp == NULL)
-		log_err("Unable to open file \"%s\" for appending: %s", config.files.setupVars.v.s, strerror(errno));
-	else
-	{
-		fprintf(fp, "WEB_PORTS=%s\n", config.webserver.port.v.s);
-		fclose(fp);
-	}
-
-	// Remove pihole.toml to prevent it from being imported on restart
-	if(remove(GLOBALTOMLPATH) != 0)
-		log_err("Unable to remove file \"%s\": %s", GLOBALTOMLPATH, strerror(errno));
-
-	// Remove all rotated pihole.toml files to avoid automatic config
-	// restore on restart
-	for(unsigned int i = MAX_ROTATIONS; i > 0; i--)
-	{
-		const char *fname = GLOBALTOMLPATH;
-		const char *filename = basename(fname);
-		// extra 6 bytes is enough space for up to 999 rotations ("/", ".", "\0", "999")
-		const size_t buflen = strlen(filename) + strlen(BACKUP_DIR) + 6;
-		char *path = calloc(buflen, sizeof(char));
-		snprintf(path, buflen, BACKUP_DIR"/%s.%u", filename, i);
-
-		// Remove file (if it exists)
-		if(remove(path) != 0 && errno != ENOENT)
-			log_err("Unable to remove file \"%s\": %s", path, strerror(errno));
-	}
-
-	// Free allocated memory
-	free_upload_data(data);
-
-	// Signal FTL we want to restart for re-import
-	api->ftl.restart = true;
-
-	// Send response
-	cJSON *json = JSON_NEW_OBJECT();
-	JSON_ADD_ITEM_TO_OBJECT(json, "files", imported_files);
-	JSON_SEND_OBJECT(json);
-}
-
 int api_teleporter(struct ftl_conn *api)
 {
 	if(api->method == HTTP_GET)
--- a/src/config/config.h
+++ b/src/config/config.h
@@ -45,9 +45,6 @@
 
 // Size of the buffer used to report possible errors during config validation
 #define VALIDATOR_ERRBUF_LEN 256
-
-// Location of the legacy (pre-v6.0) config file
-#define GLOBALCONFFILE_LEGACY "/etc/pihole/pihole-FTL.conf"
 
 union conf_value {
 	bool b;                                     // boolean value
@@ -105,8 +102,7 @@ enum conf_type {
 #define FLAG_INVALIDATE_SESSIONS   (1 << 3)
 #define FLAG_WRITE_ONLY            (1 << 4)
 #define FLAG_ENV_VAR               (1 << 5)
-#define FLAG_CONF_IMPORTED         (1 << 6)
-#define FLAG_PKG_DHCP              (1 << 7)
+#define FLAG_PKG_DHCP              (1 << 6)
 
 struct conf_item {
 	const char *k;        // item Key
--- a/src/config/legacy_reader.c
+++ b/src/config/legacy_reader.c
@@ -43,7 +43,7 @@ static FILE * __attribute__((nonnull(1),
 		return fp;
 
 	// Local file not present, try system file
-	*path = GLOBALCONFFILE_LEGACY;
+	*path = "/etc/pihole/pihole-FTL.conf";
 	fp = fopen(*path, "r");
 
 	return fp;
@@ -113,12 +113,9 @@ const char *readFTLlegacy(struct config
 	const char *path = NULL;
 	FILE *fp = openFTLconf(&path);
 	if(fp == NULL)
-	{
-		log_warn("No readable FTL config file found, using default settings");
 		return NULL;
-	}
 
-	log_info("Reading legacy config files from %s", path);
+	log_notice("Reading legacy config file");
 
 	// MAXDBDAYS
 	// defaults to: 365 days
--- a/src/config/setupVars.c
+++ b/src/config/setupVars.c
@@ -42,7 +42,6 @@ static void get_conf_string_from_setupVa
 		free(conf_item->v.s);
 	conf_item->v.s = strdup(setupVarsValue);
 	conf_item->t = CONF_STRING_ALLOCATED;
-	conf_item->f |= FLAG_CONF_IMPORTED;
 
 	// Free memory, harmless to call if read_setupVarsconf() didn't return a result
 	clearSetupVarsArray();
@@ -499,8 +498,6 @@ static void get_conf_listeningMode_from_
 
 void importsetupVarsConf(void)
 {
-	log_info("Migrating config from %s", config.files.setupVars.v.s);
-
 	// Try to obtain password hash from setupVars.conf
 	get_conf_string_from_setupVars("WEBPASSWORD", &config.webserver.api.pwhash);
 
@@ -567,26 +564,7 @@ void importsetupVarsConf(void)
 	get_conf_bool_from_setupVars("DHCP_RAPID_COMMIT", &config.dhcp.rapidCommit);
 
 	get_conf_bool_from_setupVars("queryLogging", &config.dns.queryLogging);
-
 	get_conf_string_from_setupVars("GRAVITY_TMPDIR", &config.files.gravity_tmp);
-
-	// Ports may be temporarily stored when importing a legacy Teleporter v5 file
-	get_conf_string_from_setupVars("WEB_PORTS", &config.webserver.port);
-
-	// Move the setupVars.conf file to setupVars.conf.old
-	char *old_setupVars = calloc(strlen(config.files.setupVars.v.s) + 5, sizeof(char));
-	if(old_setupVars == NULL)
-	{
-		log_warn("Could not allocate memory for old_setupVars");
-		return;
-	}
-	strcpy(old_setupVars, config.files.setupVars.v.s);
-	strcat(old_setupVars, ".old");
-	if(rename(config.files.setupVars.v.s, old_setupVars) != 0)
-		log_warn("Could not move %s to %s", config.files.setupVars.v.s, old_setupVars);
-	else
-		log_info("Moved %s to %s", config.files.setupVars.v.s, old_setupVars);
-	free(old_setupVars);
 }
 
 char* __attribute__((pure)) find_equals(char *s)
--- a/src/main.c
+++ b/src/main.c
@@ -164,7 +164,7 @@ int main (int argc, char *argv[])
 	cleanup(exit_code);
 
 	if(exit_code == RESTART_FTL_CODE)
-		execvp(argv[0], argv);
+		execv(argv[0], argv);
 
 	return exit_code;
 }
--- a/src/zip/CMakeLists.txt
+++ b/src/zip/CMakeLists.txt
@@ -11,8 +11,6 @@
 set(sources
         gzip.c
         gzip.h
-        tar.c
-        tar.h
         teleporter.c
         teleporter.h
         )
--- a/src/zip/gzip.c
+++ b/src/zip/gzip.c
@@ -14,6 +14,7 @@
 #include <string.h>
 // le32toh and friends
 #include <endian.h>
+#include "miniz/miniz.h"
 #include "gzip.h"
 #include "log.h"
 
@@ -102,8 +103,8 @@ static bool deflate_buffer(const unsigne
 	return true;
 }
 
-bool inflate_buffer(unsigned char *buffer_compressed, mz_ulong size_compressed,
-                    unsigned char **buffer_uncompressed, mz_ulong *size_uncompressed)
+static bool inflate_buffer(unsigned char *buffer_compressed, mz_ulong size_compressed,
+                           unsigned char **buffer_uncompressed, mz_ulong *size_uncompressed)
 {
 	// Check GZIP header (magic byte 1F 8B and compression algorithm deflate 08)
 	if(buffer_compressed[0] != 0x1F || buffer_compressed[1] != 0x8B)
--- a/src/zip/gzip.h
+++ b/src/zip/gzip.h
@@ -11,10 +11,6 @@
 #define GZIP_H
 
 #include <stdbool.h>
-#include "miniz/miniz.h"
-
-bool inflate_buffer(unsigned char *buffer_compressed, mz_ulong size_compressed,
-                    unsigned char **buffer_uncompressed, mz_ulong *size_uncompressed);
 
 bool deflate_file(const char *in, const char *out, bool verbose);
 bool inflate_file(const char *infile, const char *outfile, bool verbose);
--- a/src/zip/teleporter.c
+++ b/src/zip/teleporter.c
@@ -527,7 +527,7 @@ static const char *test_and_import_datab
 	return NULL;
 }
 
-const char *read_teleporter_zip(uint8_t *buffer, const size_t buflen, char * const hint, cJSON *imported_files)
+const char *read_teleporter_zip(char *buffer, const size_t buflen, char * const hint, cJSON *imported_files)
 {
 	// Initialize ZIP archive
 	mz_zip_archive zip = { 0 };
--- a/src/zip/teleporter.h
+++ b/src/zip/teleporter.h
@@ -19,7 +19,7 @@
 
 const char *generate_teleporter_zip(mz_zip_archive *zip, char filename[128], void **ptr, size_t *size);
 bool free_teleporter_zip(mz_zip_archive *zip);
-const char *read_teleporter_zip(uint8_t *buffer, const size_t buflen, char *hint, cJSON *json_files);
+const char *read_teleporter_zip(char *buffer, const size_t buflen, char *hint, cJSON *json_files);
 
 bool write_teleporter_zip_to_disk(void);
 bool read_teleporter_zip_from_disk(const char *filename);
